\section{Feedforwards}

Feedforwards are used to inject information about either the \gls{system}'s
dynamics (like a \gls{model} does) or the intended movement into a controller.
Feedforward is generally used to handle parts of the control actions we already
know must be applied to make a \gls{system} track a \gls{reference}, then let
the feedback controller correct for at runtime what we do not or cannot know
about the \gls{system}. We will present two ways of implementing feedforward for
\gls{state} feedback.

\subsection{Steady-state feedforward}

Steady-state feedforwards apply the \gls{control effort} required to keep a
\gls{system} at the \gls{reference} if it is no longer moving (i.e., the
\gls{system} is at steady-state). The first steady-state feedforward converts
desired \glspl{output} to desired \glspl{state}.

\begin{equation*}
  \mtx{x}_c = \mtx{N}_x\mtx{y}_c
\end{equation*}

$\mtx{N}_x$ converts desired \glspl{output} $\mtx{y}_c$ to desired \glspl{state}
$\mtx{x}_c$ (also known as $\mtx{r}$). For steady-state, that is

\begin{equation}
  \mtx{x}_{ss} = \mtx{N}_x\mtx{y}_{ss} \label{eq:x_ss}
\end{equation}

The second steady-state feedforward converts the desired \glspl{output}
$\mtx{y}$ to the \gls{control input} required at steady-state.

\begin{equation*}
  \mtx{u}_c = \mtx{N}_u\mtx{y}_c
\end{equation*}

$\mtx{N}_u$ converts the desired \glspl{output} $\mtx{y}$ to the
\gls{control input} $\mtx{u}$ required at steady-state. For steady-state, that
is

\begin{equation}
  \mtx{u}_{ss} = \mtx{N}_u\mtx{y}_{ss} \label{eq:u_ss}
\end{equation}

\subsubsection{Continuous case}

To find the \gls{control input} required at steady-state, set equation
(\ref{eq:ss_ctrl_x}) to zero.

\begin{align*}
  \dot{\mtx{x}} &= \mtx{A}\mtx{x} + \mtx{B}\mtx{u} \\
  \mtx{y} &= \mtx{C}\mtx{x} + \mtx{D}\mtx{u}
\end{align*}

\begin{align*}
  \mtx{0} &= \mtx{A}\mtx{x}_{ss} + \mtx{B}\mtx{u}_{ss} \\
  \mtx{y}_{ss} &= \mtx{C}\mtx{x}_{ss} + \mtx{D}\mtx{u}_{ss}
\end{align*}

\begin{align*}
  \mtx{0} &= \mtx{A}\mtx{N}_x\mtx{y}_{ss} + \mtx{B}\mtx{N}_u\mtx{y}_{ss} \\
  \mtx{y}_{ss} &= \mtx{C}\mtx{N}_x\mtx{y}_{ss} + \mtx{D}\mtx{N}_u\mtx{y}_{ss}
\end{align*}

\begin{align*}
  \begin{bmatrix}
    \mtx{0} \\
    \mtx{y}_{ss}
  \end{bmatrix} &=
  \begin{bmatrix}
    \mtx{A}\mtx{N}_x + \mtx{B}\mtx{N}_u \\
    \mtx{C}\mtx{N}_x + \mtx{D}\mtx{N}_u
  \end{bmatrix}
  \mtx{y}_{ss} \\
  \begin{bmatrix}
    \mtx{0} \\
    \mtx{1}
  \end{bmatrix} &=
  \begin{bmatrix}
    \mtx{A}\mtx{N}_x + \mtx{B}\mtx{N}_u \\
    \mtx{C}\mtx{N}_x + \mtx{D}\mtx{N}_u
  \end{bmatrix} \\
  \begin{bmatrix}
    \mtx{0} \\
    \mtx{1}
  \end{bmatrix} &=
  \begin{bmatrix}
    \mtx{A} & \mtx{B} \\
    \mtx{C} & \mtx{D}
  \end{bmatrix}
  \begin{bmatrix}
    \mtx{N}_x \\
    \mtx{N}_u
  \end{bmatrix} \\
  \begin{bmatrix}
    \mtx{N}_x \\
    \mtx{N}_u
  \end{bmatrix} &=
  \begin{bmatrix}
    \mtx{A} & \mtx{B} \\
    \mtx{C} & \mtx{D}
  \end{bmatrix}^{\dagger}
  \begin{bmatrix}
    \mtx{0} \\
    \mtx{1}
  \end{bmatrix}
\end{align*}

where $^\dagger$ is the Moore-Penrose pseudoinverse.

\subsubsection{Discrete case}

Now, we'll do the same thing for the discrete \gls{system}. To find the
\gls{control input} required at steady-state, set equation (\ref{eq:ssz_ctrl_x})
to zero.

\begin{align*}
  \mtx{x}_{k+1} &= \mtx{A}\mtx{x}_k + \mtx{B}\mtx{u}_k \\
  \mtx{y}_k &= \mtx{C}\mtx{x}_k + \mtx{D}\mtx{u}_k
\end{align*}

\begin{align*}
  \mtx{x}_{ss} &= \mtx{A}\mtx{x}_{ss} + \mtx{B}\mtx{u}_{ss} \\
  \mtx{y}_{ss} &= \mtx{C}\mtx{x}_{ss} + \mtx{D}\mtx{u}_{ss}
\end{align*}

\begin{align*}
  \mtx{0} &= (\mtx{A} - \mtx{I})\mtx{x}_{ss} + \mtx{B}\mtx{u}_{ss} \\
  \mtx{y}_{ss} &= \mtx{C}\mtx{x}_{ss} + \mtx{D}\mtx{u}_{ss}
\end{align*}

\begin{align*}
  \mtx{0} &= (\mtx{A} - \mtx{I})\mtx{N}_x\mtx{y}_{ss} +
    \mtx{B}\mtx{N}_u\mtx{y}_{ss} \\
  \mtx{y}_{ss} &= \mtx{C}\mtx{N}_x\mtx{y}_{ss} + \mtx{D}\mtx{N}_u\mtx{y}_{ss}
\end{align*}

\begin{align*}
  \begin{bmatrix}
    \mtx{0} \\
    \mtx{y}_{ss}
  \end{bmatrix} &=
  \begin{bmatrix}
    (\mtx{A} - \mtx{I})\mtx{N}_x + \mtx{B}\mtx{N}_u \\
    \mtx{C}\mtx{N}_x + \mtx{D}\mtx{N}_u
  \end{bmatrix}
  \mtx{y}_{ss} \\
  \begin{bmatrix}
    \mtx{0} \\
    \mtx{1}
  \end{bmatrix} &=
  \begin{bmatrix}
    (\mtx{A} - \mtx{I})\mtx{N}_x + \mtx{B}\mtx{N}_u \\
    \mtx{C}\mtx{N}_x + \mtx{D}\mtx{N}_u
  \end{bmatrix} \\
  \begin{bmatrix}
    \mtx{0} \\
    \mtx{1}
  \end{bmatrix} &=
  \begin{bmatrix}
    \mtx{A} - \mtx{I} & \mtx{B} \\
    \mtx{C} & \mtx{D}
  \end{bmatrix}
  \begin{bmatrix}
    \mtx{N}_x \\
    \mtx{N}_u
  \end{bmatrix} \\
  \begin{bmatrix}
    \mtx{N}_x \\
    \mtx{N}_u
  \end{bmatrix} &=
  \begin{bmatrix}
    \mtx{A} - \mtx{I} & \mtx{B} \\
    \mtx{C} & \mtx{D}
  \end{bmatrix}^{\dagger}
  \begin{bmatrix}
    \mtx{0} \\
    \mtx{1}
  \end{bmatrix}
\end{align*}

where $^\dagger$ is the Moore-Penrose pseudoinverse.

\subsubsection{Deriving steady-state input}

Now, we'll find an expression that uses $\mtx{N}_x$ and $\mtx{N}_u$ to convert
the \gls{reference} $\mtx{r}$ to a \gls{control input} feedforward
$\mtx{u}_{ff}$. Let's start with equation (\ref{eq:x_ss}).

\begin{align*}
  \mtx{x}_{ss} &= \mtx{N}_x \mtx{y}_{ss} \\
  \mtx{N}_x^\dagger \mtx{x}_{ss} &= \mtx{y}_{ss}
\end{align*}

Now substitute this into equation (\ref{eq:u_ss}).

\begin{align*}
  \mtx{u}_{ss} &= \mtx{N}_u \mtx{y}_{ss} \\
  \mtx{u}_{ss} &= \mtx{N}_u (\mtx{N}_x^\dagger \mtx{x}_{ss}) \\
  \mtx{u}_{ss} &= \mtx{N}_u \mtx{N}_x^\dagger \mtx{x}_{ss}
\end{align*}

$\mtx{u}_{ss}$ and $\mtx{x}_{ss}$ are also known as $\mtx{u}_{ff}$ and $\mtx{r}$
respectively.

\begin{align*}
  \mtx{u}_{ff} = \mtx{N}_u \mtx{N}_x^\dagger \mtx{r}
\end{align*}

So all together, we get theorem \ref{thm:steady-state_ff}.

\index{Feedforward!steady-state feedforward}
\begin{theorem}[Steady-state feedforward]
  \label{thm:steady-state_ff}

  \begin{align}
    &\text{Continuous:} \nonumber \\
    &\begin{bmatrix}
      \mtx{N}_x \\
      \mtx{N}_u
    \end{bmatrix} =
    \begin{bmatrix}
      \mtx{A} & \mtx{B} \\
      \mtx{C} & \mtx{D}
    \end{bmatrix}^{\dagger}
    \begin{bmatrix}
      \mtx{0} \\
      \mtx{1}
    \end{bmatrix} \\
    &\text{Discrete:} \nonumber \\
    &\begin{bmatrix}
      \mtx{N}_x \\
      \mtx{N}_u
    \end{bmatrix} =
    \begin{bmatrix}
      \mtx{A} - \mtx{I} & \mtx{B} \\
      \mtx{C} & \mtx{D}
    \end{bmatrix}^{\dagger}
    \begin{bmatrix}
      \mtx{0} \\
      \mtx{1}
    \end{bmatrix}
  \end{align}

  \begin{equation}
    \mtx{u}_{ff} = \mtx{N}_u \mtx{N}_x^\dagger \mtx{r}
  \end{equation}

  In the augmented matrix, $\mtx{B}$ should contain one column corresponding to
  an actuator and $\mtx{C}$ should contain one row whose \gls{output} will be
  driven by that actuator. More than one actuator or output can be included in
  the computation at once, but the result won't be the same as if they were
  computed independently and summed afterward.

  After computing the feedforward for each actuator-output pair, the respective
  collections of $\mtx{N}_x$ and $\mtx{N}_u$ matrices can summed to produce the
  combined feedforward.
\end{theorem}

If the augmented matrix in theorem \ref{thm:steady-state_ff} is square (number
of \glspl{input} = number of \glspl{output}), the normal matrix inverse can be
used instead.

\subsection{Two-state feedforward}

Let's start with the equation for the \gls{reference} dynamics

\begin{equation*}
  \mtx{r}_{k+1} = \mtx{A}\mtx{r}_k + \mtx{B}\mtx{u}_{ff}
\end{equation*}

where $\mtx{u}_{ff}$ is the feedforward input. Note that this feedforward
equation does not and should not take into account any feedback terms. We want
to find the optimal $\mtx{u}_{ff}$ such that we minimize the \gls{tracking}
error between $\mtx{r}_{k+1}$ and $\mtx{r}_k$.

\begin{equation*}
  \mtx{r}_{k+1} - \mtx{A}\mtx{r}_k = \mtx{B}\mtx{u}_{ff}
\end{equation*}

To solve for $\mtx{u}_{ff}$, we need to take the inverse of the nonsquare matrix
$\mtx{B}$. This isn't possible, but we can find the pseudoinverse given some
constraints on the \gls{state} \gls{tracking} error and \gls{control effort}. To
find the optimal solution for these sorts of trade-offs, one can define a cost
function and attempt to minimize it. To do this, we'll first solve the
expression for $\mtx{0}$.

\begin{equation*}
  \mtx{0} = \mtx{B}\mtx{u}_{ff} - (\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k)
\end{equation*}

This expression will be the \gls{state} \gls{tracking} cost we use in our cost
function.

Our cost function will use an $H_2$ norm with $\mtx{Q}$ as the \gls{state} cost
matrix with dimensionality $states \times states$ and $\mtx{R}$ as the
\gls{control input} cost matrix with dimensionality $inputs \times inputs$.

\begin{equation*}
  \mtx{J} = (\mtx{B}\mtx{u}_{ff} - (\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k))^T \mtx{Q}
    (\mtx{B}\mtx{u}_{ff} - (\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k)) +
    \mtx{u}_{ff}^T\mtx{R}\mtx{u}_{ff}
\end{equation*}

\begin{remark}
  $\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k$ will only return a nonzero vector if the
  \gls{reference} isn't following the \gls{system} dynamics. If it is, the
  feedback controller already compensates for it. This feedforward compensates
  for any unmodeled dynamics reflected in how the \gls{reference} is changing
  (or not changing). In the case of a constant \gls{reference}, the feedforward
  opposes any \gls{system} dynamics that would change the \gls{state} over time.
\end{remark}

The following theorems will be needed to find the minimum of $\mtx{J}$.

\begin{theorem}
  \label{thm:partial_xax}

  $\frac{\partial \mtx{x}^T\mtx{A}\mtx{x}}{\partial\mtx{x}} =
    2\mtx{A}\mtx{x}$ where $\mtx{A}$ is symmetric.
\end{theorem}

\begin{theorem}
  \label{thm:partial_ax_b}

  $\frac{\partial (\mtx{A}\mtx{x} + \mtx{b})^T\mtx{C}
    (\mtx{D}\mtx{x} + \mtx{e})}{\partial\mtx{x}} =
    \mtx{A}^T\mtx{C}(\mtx{D}\mtx{x} + \mtx{e}) + \mtx{D}^T\mtx{C}^T
    (\mtx{A}\mtx{x} + \mtx{b})$
\end{theorem}

\begin{corollary}
  \label{cor:partial_ax_b}

  $\frac{\partial (\mtx{A}\mtx{x} + \mtx{b})^T\mtx{C}
    (\mtx{A}\mtx{x} + \mtx{b})}{\partial\mtx{x}} =
    2\mtx{A}^T\mtx{C}(\mtx{A}\mtx{x} + \mtx{b})$ where $\mtx{C}$ is symmetric.

  Proof:
  \begin{align*}
    \frac{\partial (\mtx{A}\mtx{x} + \mtx{b})^T\mtx{C}
      (\mtx{A}\mtx{x} + \mtx{b})}{\partial\mtx{x}} &=
      \mtx{A}^T\mtx{C}(\mtx{A}\mtx{x} + \mtx{b}) + \mtx{A}^T\mtx{C}^T
      (\mtx{A}\mtx{x} + \mtx{b}) \\
    \frac{\partial (\mtx{A}\mtx{x} + \mtx{b})^T\mtx{C}
      (\mtx{A}\mtx{x} + \mtx{b})}{\partial\mtx{x}} &=
      (\mtx{A}^T\mtx{C} + \mtx{A}^T\mtx{C}^T)(\mtx{A}\mtx{x} + \mtx{b})
  \end{align*}

  $\mtx{C}$ is symmetric, so

  \begin{align*}
    \frac{\partial (\mtx{A}\mtx{x} + \mtx{b})^T\mtx{C}
      (\mtx{A}\mtx{x} + \mtx{b})}{\partial\mtx{x}} &=
      (\mtx{A}^T\mtx{C} + \mtx{A}^T\mtx{C})(\mtx{A}\mtx{x} + \mtx{b}) \\
    \frac{\partial (\mtx{A}\mtx{x} + \mtx{b})^T\mtx{C}
      (\mtx{A}\mtx{x} + \mtx{b})}{\partial\mtx{x}} &=
      2\mtx{A}^T\mtx{C}(\mtx{A}\mtx{x} + \mtx{b})
  \end{align*}
\end{corollary}

Given theorem \ref{thm:partial_xax} and corollary \ref{cor:partial_ax_b}, find
the minimum of $\mtx{J}$ by taking the partial derivative with respect to
$\mtx{u}_{ff}$ and setting the result to $\mtx{0}$.

\begin{align*}
  \frac{\partial\mtx{J}}{\partial\mtx{u}_{ff}} &= 2\mtx{B}^T\mtx{Q}
    (\mtx{B}\mtx{u}_{ff} - (\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k)) +
    2\mtx{R}\mtx{u}_{ff} \\
  \mtx{0} &= 2\mtx{B}^T\mtx{Q}
    (\mtx{B}\mtx{u}_{ff} - (\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k)) +
    2\mtx{R}\mtx{u}_{ff} \\
  \mtx{0} &= \mtx{B}^T\mtx{Q}
    (\mtx{B}\mtx{u}_{ff} - (\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k)) +
    \mtx{R}\mtx{u}_{ff} \\
  \mtx{0} &= \mtx{B}^T\mtx{Q}\mtx{B}\mtx{u}_{ff} -
    \mtx{B}^T\mtx{Q}(\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k) + \mtx{R}\mtx{u}_{ff} \\
  \mtx{B}^T\mtx{Q}\mtx{B}\mtx{u}_{ff} + \mtx{R}\mtx{u}_{ff} &=
    \mtx{B}^T\mtx{Q}(\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k) \\
  (\mtx{B}^T\mtx{Q}\mtx{B} + \mtx{R})\mtx{u}_{ff} &=
    \mtx{B}^T\mtx{Q}(\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k) \\
  \mtx{u}_{ff} &= (\mtx{B}^T\mtx{Q}\mtx{B} + \mtx{R})^{-1}
    \mtx{B}^T\mtx{Q}(\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k)
\end{align*}

\begin{theorem}[Two-state feedforward]
  \label{thm:two-state_ff}

  \begin{align}
    &\mtx{u}_{ff} = \mtx{K}_{ff} (\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k) \\
    &\text{where } \mtx{K}_{ff} =
      (\mtx{B}^T\mtx{Q}\mtx{B} + \mtx{R})^{-1}\mtx{B}^T\mtx{Q}
  \end{align}
\end{theorem}
\index{Feedforward!two-state feedforward}
\index{Optimal control!two-state feedforward}

If \gls{control effort} is considered inexpensive, $\mtx{R} \ll \mtx{Q}$ and
$\mtx{u}_{ff}$ approaches corollary \ref{cor:two-state_ff_no_r}.

\begin{corollary}[Two-state feedforward with inexpensive control effort]
  \label{cor:two-state_ff_no_r}

  \begin{align}
    &\mtx{u}_{ff} = \mtx{K}_{ff} (\mtx{r}_{k+1} - \mtx{A}\mtx{r}_k) \\
    &\text{where } \mtx{K}_{ff} =
      (\mtx{B}^T\mtx{Q}\mtx{B})^{-1}\mtx{B}^T\mtx{Q}
  \end{align}
\end{corollary}

\begin{remark}
  If the cost matrix $\mtx{Q}$ isn't included in the cost function (that is,
  $\mtx{Q}$ is set to the identity matrix), $\mtx{K}_{ff}$ becomes the
  Moore-Penrose pseudoinverse of $\mtx{B}$ given by
  $\mtx{B}^\dagger = (\mtx{B}^T\mtx{B})^{-1}\mtx{B}^T$.
\end{remark}

\subsection{Case studies of feedforwards}

\subsubsection{Second-order CIM motor model}

Each feedforward implementation has advantages. The steady-state feedforward
allows using specific actuators to maintain the \gls{reference} at steady-state.
The two-state feedforward doesn't support this, but can be used for
\gls{reference} \gls{tracking} as well with the same tuning parameters as LQR
design. Figure \ref{fig:case_study_ff1} shows both types of feedforwards applied
to a second-order CIM motor model.

\begin{svg}{build/code/case_study_ff1}
  \caption{Second-order CIM motor response with various feedforwards}
  \label{fig:case_study_ff1}
\end{svg}

The two-state feedforward isn't as effective in figure \ref{fig:case_study_ff1}
because the $\mtx{R}$ matrix penalized \gls{control effort}. If the $\mtx{R}$
cost matrix is removed from the two-state feedforward calculation, the
\gls{reference} \gls{tracking} is much better (see figure
\ref{fig:case_study_ff2}).

\begin{svg}{build/code/case_study_ff2}
  \caption{Second-order CIM motor response with two-state feedforwards}
  \label{fig:case_study_ff2}
\end{svg}
