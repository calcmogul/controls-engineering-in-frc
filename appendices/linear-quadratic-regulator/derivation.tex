\section{Derivation}
\label{sec:lqr_derivation}

Let there be a discrete time linear \gls{system} defined as
\begin{equation}
  \mat{x}_{k+1} = \mat{A}\mat{x}_k + \mat{B}\mat{u}_k
\end{equation}

with the cost functional
\begin{equation*}
  J = \sum_{k=0}^\infty
    \begin{bmatrix}
      \mat{x}_k \\
      \mat{u}_k
    \end{bmatrix}\T
    \begin{bmatrix}
      \mat{Q} & \mat{N} \\
      \mat{N}\T & \mat{R}
    \end{bmatrix}
    \begin{bmatrix}
      \mat{x}_k \\
      \mat{u}_k
    \end{bmatrix}
\end{equation*}

where $J$ represents a trade-off between \gls{state} excursion and
\gls{control effort} with the weighting factors $\mat{Q}$, $\mat{R}$, and
$\mat{N}$. $\mat{Q}$ is the weight matrix for \gls{error}, $\mat{R}$ is the
weight matrix for \gls{control effort}, and $\mat{N}$ is a cross weight matrix
between \gls{error} and \gls{control effort}. $\mat{N}$ is commonly utilized
when penalizing the output in addition to the state and input.
\begin{align*}
  J &= \sum_{k=0}^\infty
    \begin{bmatrix}
      \mat{x}_k \\
      \mat{u}_k
    \end{bmatrix}\T
    \begin{bmatrix}
      \mat{Q}\mat{x}_k + \mat{N}\mat{u}_k \\
      \mat{N}\T\mat{x}_k + \mat{R}\mat{u}_k
    \end{bmatrix} \\
  J &= \sum_{k=0}^\infty
    \begin{bmatrix}
      \mat{x}_k\T & \mat{u}_k\T
    \end{bmatrix}
    \begin{bmatrix}
      \mat{Q}\mat{x}_k + \mat{N}\mat{u}_k \\
      \mat{N}\T\mat{x}_k + \mat{R}\mat{u}_k
    \end{bmatrix} \\
  J &= \sum_{k=0}^\infty
    (\mat{x}_k\T (\mat{Q}\mat{x}_k + \mat{N}\mat{u}_k) +
      \mat{u}_k\T (\mat{N}\T\mat{x}_k + \mat{R}\mat{u}_k)) \\
  J &= \sum_{k=0}^\infty
    (\mat{x}_k\T\mat{Q}\mat{x}_k + \mat{x}_k\T\mat{N}\mat{u}_k +
      \mat{u}_k\T\mat{N}\T\mat{x}_k + \mat{u}_k\T\mat{R}\mat{u}_k) \\
  J &= \sum_{k=0}^\infty
    (\mat{x}_k\T\mat{Q}\mat{x}_k + \mat{x}_k\T\mat{N}\mat{u}_k +
      \mat{x}_k\T\mat{N}\mat{u}_k\T + \mat{u_k}\T\mat{R}\mat{u}_k) \\
  J &= \sum_{k=0}^\infty
    (\mat{x}_k\T\mat{Q}\mat{x}_k + 2\mat{x}_k\T\mat{N}\mat{u}_k +
      \mat{u}_k\T\mat{R}\mat{u}_k) \\
  J &= \sum_{k=0}^\infty
    (\mat{x}_k\T\mat{Q}\mat{x}_k + \mat{u}_k\T\mat{R}\mat{u}_k +
      2\mat{x}_k\T\mat{N}\mat{u}_k)
\end{align*}

The feedback \gls{control law} which minimizes $J$ subject to the constraint
$\mat{x}_{k+1} = \mat{A}\mat{x}_k + \mat{B}\mat{u}_k$ is
\begin{equation*}
  \mat{u}_k = -\mat{K}\mat{x}_k
\end{equation*}

where $\mat{K}$ is given by
\begin{equation*}
  \mat{K} = (\mat{R} + \mat{B}\T\mat{P}\mat{B})^{-1}
    (\mat{B}\T\mat{P}\mat{A} + \mat{N}\T)
\end{equation*}

and $\mat{P}$ is found by solving the discrete time algebraic Riccati equation
defined as
\begin{equation*}
  \mat{A}\T\mat{P}\mat{A} - \mat{P} - (\mat{A}\T\mat{P}\mat{B} + \mat{N})
    (\mat{R} + \mat{B}\T\mat{P}\mat{B})^{-1}
    (\mat{B}\T\mat{P}\mat{A} + \mat{N}\T) + \mat{Q} = 0
\end{equation*}

or alternatively
\begin{equation*}
  \mathcal{A}\T\mat{P}\mathcal{A} - \mat{P} - \mathcal{A}\T\mat{P}\mat{B}
    (\mat{R} + \mat{B}\T\mat{P}\mat{B})^{-1} \mat{B}\T\mat{P}\mathcal{A} +
    \mat{Q} = 0
\end{equation*}

with
\begin{align*}
  \mathcal{A} &= \mat{A} - \mat{B}\mat{R}^{-1}\mat{N}\T \\
  \mathcal{Q} &= \mat{Q} - \mat{N}\mat{R}^{-1}\mat{N}\T
\end{align*}

If there is no cross-correlation between \gls{error} and \gls{control effort},
$\mat{N}$ is a zero matrix and the cost functional simplifies to
\begin{equation*}
  J = \sum_{k=0}^\infty (\mat{x}_k\T\mat{Q}\mat{x}_k +
    \mat{u}_k\T\mat{R}\mat{u}_k)
\end{equation*}

The feedback \gls{control law} which minimizes this $J$ subject to
$\mat{x}_{k+1} = \mat{A}\mat{x}_k + \mat{B}\mat{u}_k$ is
\begin{equation*}
  \mat{u}_k = -\mat{K}\mat{x}_k
\end{equation*}

where $\mat{K}$ is given by
\begin{equation*}
  \mat{K} = (\mat{R} + \mat{B}\T\mat{P}\mat{B})^{-1} \mat{B}\T\mat{P}\mat{A}
\end{equation*}

and $\mat{P}$ is found by solving the discrete time algebraic Riccati equation
defined as
\begin{equation*}
  \mat{A}\T\mat{P}\mat{A} - \mat{P} - \mat{A}\T\mat{P}\mat{B}
    (\mat{R} + \mat{B}\T\mat{P}\mat{B})^{-1} \mat{B}\T\mat{P}\mat{A} +
    \mat{Q} = 0
\end{equation*}

Snippets \ref{lst:lqr_cpp} and \ref{lst:lqr_py} compute the infinite horizon,
discrete time LQR.
\begin{coderemote}{cpp}{snippets/LQR.cpp}
  \caption{Infinite horizon, discrete time LQR solver in C++ (see subsection
    \ref{subsec:dare} for DARE solver)}
  \label{lst:lqr_cpp}
\end{coderemote}
\begin{coderemote}{Python}{snippets/lqr.py}
  \caption{Infinite horizon, discrete time LQR solver in Python}
  \label{lst:lqr_py}
\end{coderemote}

Other formulations of LQR for finite horizon and discrete time can be seen on
Wikipedia.\footnote{\url{https://en.wikipedia.org/wiki/Linear-quadratic_regulator}}

The course notes for MIT 6.832 \textit{Underactuated Robotics: Algorithms for
Walking, Running, Swimming, Flying, and Manipulation} by Russ Tedrake have a
rigorous proof of the results shown
above.\footnote{\url{https://underactuated.mit.edu/lqr.html}}
