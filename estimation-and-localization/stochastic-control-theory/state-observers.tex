\section{State observers}

State \glspl{observer} are used to estimate \glspl{state} which cannot be
measured directly. This can be due to noisy measurements or the \gls{state} not
being measurable (a hidden \gls{state}). This information can be used for
\gls{localization}, which is the process of using external measurements to
determine an \gls{agent}'s pose,\footnote{An agent is a system-agnostic term for
independent controlled actors like robots or aircraft.} or orientation in the
world.

One type of \gls{state} estimator is LQE. ``LQE" stands for ``Linear-Quadratic
Estimator". Similar to LQR, it places the estimator poles such that it minimizes
the sum of squares of the estimation \gls{error}. The Luenberger \gls{observer}
and Kalman filter are examples of these, where the latter chooses the pole
locations optimally based on the \gls{model} and measurement uncertainties.

Computer vision can also be used for \gls{localization}. By extracting features
from an image taken by the \gls{agent}'s camera, like a retroreflective target
in FRC, and comparing them to known dimensions, one can determine where the
\gls{agent}'s camera would have to be to see that image. This can be used to
correct our \gls{state} estimate in the same way we do with an encoder or
gyroscope.

\subsection{Luenberger observer}
\index{state-space observers!Luenberger observer}

We'll introduce the Luenberger observer first to demonstrate the general form of
a state estimator and some of their properties.
\begin{theorem}[Luenberger observer]
  \begin{align}
    \dot{\hat{\mat{x}}} &= \mat{A}\hat{\mat{x}} + \mat{B}\mat{u} +
      \mat{L} (\mat{y} - \hat{\mat{y}}) \\
    \hat{\mat{y}} &= \mat{C}\hat{\mat{x}} + \mat{D}\mat{u}
  \end{align}
  \begin{align}
    \hat{\mat{x}}_{k+1} &= \mat{A}\hat{\mat{x}}_k + \mat{B}\mat{u}_k +
      \mat{L}(\mat{y}_k - \hat{\mat{y}}_k) \label{eq:z_obsv_x} \\
    \hat{\mat{y}}_k &= \mat{C}\hat{\mat{x}}_k + \mat{D}\mat{u}_k
      \label{eq:z_obsv_y} \\ \nonumber
  \end{align}
  \begin{figurekey}
    \begin{tabular}{llll}
      $\mat{A}$ & system matrix      & $\hat{\mat{x}}$ & state estimate vector \\
      $\mat{B}$ & input matrix       & $\mat{u}$ & input vector \\
      $\mat{C}$ & output matrix      & $\mat{y}$ & output vector \\
      $\mat{D}$ & feedthrough matrix & $\hat{\mat{y}}$ & output estimate vector \\
      $\mat{L}$ & estimator gain matrix & & \\
    \end{tabular}
  \end{figurekey}
\end{theorem}
\begin{booktable}
  \begin{tabular}{|ll|ll|}
    \hline
    \rowcolor{headingbg}
    \textbf{Matrix} & \textbf{Rows $\times$ Columns} &
    \textbf{Matrix} & \textbf{Rows $\times$ Columns} \\
    \hline
    $\mat{A}$ & states $\times$ states & $\hat{\mat{x}}$ & states $\times$ 1 \\
    $\mat{B}$ & states $\times$ inputs & $\mat{u}$ & inputs $\times$ 1 \\
    $\mat{C}$ & outputs $\times$ states & $\mat{y}$ & outputs $\times$ 1 \\
    $\mat{D}$ & outputs $\times$ inputs & $\hat{\mat{y}}$ & outputs $\times$ 1 \\
    $\mat{L}$ & states $\times$ outputs & & \\
    \hline
  \end{tabular}
  \caption{Luenberger observer matrix dimensions}
\end{booktable}

Variables denoted with a hat are estimates of the corresponding variable. For
example, $\hat{\mat{x}}$ is the estimate of the true \gls{state} $\mat{x}$.

Notice that a Luenberger \gls{observer} has an extra term in the \gls{state}
evolution equation. This term uses the difference between the estimated
\glspl{output} and measured \glspl{output} to steer the estimated \gls{state}
toward the true \gls{state}. $\mat{L}$ approaching $\mat{C}^+$ trusts the
measurements more while $\mat{L}$ approaching $\mat{0}$ trusts the \gls{model}
more.
\begin{remark}
  Using an estimator forfeits the performance guarantees from earlier
  \cite{bib:lqg_guaranteed_margins}, but the responses are still generally very
  good if the process and measurement noises are small enough.
\end{remark}

A Luenberger \gls{observer} combines the prediction and update steps of an
estimator. To run them separately, use the equations in theorem
\ref{thm:luenberger} instead.
\begin{theorem}[Luenberger observer with separate predict/update]
  \label{thm:luenberger}
  \begin{align}
    \text{Predict step} \nonumber \\
    \hat{\mat{x}}_{k+1}^- &= \mat{A}\hat{\mat{x}}_k^- + \mat{B}\mat{u}_k \\
    \text{Update step} \nonumber \\
    \hat{\mat{x}}_{k+1}^+ &= \hat{\mat{x}}_{k+1}^- + \mat{A}^{-1}\mat{L}
      (\mat{y}_k - \hat{\mat{y}}_k) \\
    \hat{\mat{y}}_k &= \mat{C} \hat{\mat{x}}_k^-
  \end{align}
\end{theorem}

See appendix \ref{subsec:deriv_luenberger_separate} for a derivation.

\subsubsection{Eigenvalues of closed-loop observer}
\index{stability!eigenvalues}

The eigenvalues of the system matrix can be used to determine whether a
\gls{state} \gls{observer}'s estimate will converge to the true \gls{state}.

Plugging equation \eqref{eq:z_obsv_y} into equation \eqref{eq:z_obsv_x} gives
\begin{align*}
  \hat{\mat{x}}_{k+1} &= \mat{A}\hat{\mat{x}}_k + \mat{B}\mat{u}_k +
    \mat{L} (\mat{y}_k - \hat{\mat{y}}_k) \\
  \hat{\mat{x}}_{k+1} &= \mat{A}\hat{\mat{x}}_k + \mat{B}\mat{u}_k +
    \mat{L} (\mat{y}_k - (\mat{C}\hat{\mat{x}}_k + \mat{D}\mat{u}_k)) \\
  \hat{\mat{x}}_{k+1} &= \mat{A}\hat{\mat{x}}_k + \mat{B}\mat{u}_k +
    \mat{L} (\mat{y}_k - \mat{C}\hat{\mat{x}}_k - \mat{D}\mat{u}_k)
  \intertext{Plugging in $\mat{y}_k = \mat{C}\mat{x}_k + \mat{D}\mat{u}_k$
    gives}
  \hat{\mat{x}}_{k+1} &= \mat{A}\hat{\mat{x}}_k + \mat{B}\mat{u}_k +
    \mat{L}((\mat{C}\mat{x}_k + \mat{D}\mat{u}_k) - \mat{C}\hat{\mat{x}}_k -
    \mat{D}\mat{u}_k) \\
  \hat{\mat{x}}_{k+1} &= \mat{A}\hat{\mat{x}}_k + \mat{B}\mat{u}_k +
    \mat{L}(\mat{C}\mat{x}_k + \mat{D}\mat{u}_k - \mat{C}\hat{\mat{x}}_k -
    \mat{D}\mat{u}_k) \\
  \hat{\mat{x}}_{k+1} &= \mat{A}\hat{\mat{x}}_k + \mat{B}\mat{u}_k +
    \mat{L}(\mat{C}\mat{x}_k - \mat{C}\hat{\mat{x}}_k) \\
  \hat{\mat{x}}_{k+1} &= \mat{A}\hat{\mat{x}}_k + \mat{B}\mat{u}_k +
    \mat{L}\mat{C}(\mat{x}_k - \hat{\mat{x}}_k)
  \intertext{Let $\mat{e}_k = \mat{x}_k - \hat{\mat{x}}_k$ be the \gls{error} in
    the estimate $\hat{\mat{x}}_k$.}
  \hat{\mat{x}}_{k+1} &= \mat{A}\hat{\mat{x}}_k + \mat{B}\mat{u}_k +
    \mat{L}\mat{C}\mat{e}_k
\end{align*}

Subtracting this from $\mat{x}_{k+1} = \mat{A}\mat{x}_k + \mat{B}\mat{u}_k$
gives
\begin{align}
  \mat{x}_{k+1} - \hat{\mat{x}}_{k+1} &= \mat{A}\mat{x}_k + \mat{B}\mat{u}_k -
    (\mat{A}\hat{\mat{x}}_k + \mat{B}\mat{u}_k +
     \mat{L}\mat{C}\mat{e}_k) \nonumber \\
  \mat{e}_{k+1} &= \mat{A}\mat{x}_k + \mat{B}\mat{u}_k -
    (\mat{A}\hat{\mat{x}}_k + \mat{B}\mat{u}_k + \mat{L}\mat{C}\mat{e}_k)
    \nonumber \\
  \mat{e}_{k+1} &= \mat{A}\mat{x}_k + \mat{B}\mat{u}_k -
    \mat{A}\hat{\mat{x}}_k - \mat{B}\mat{u}_k - \mat{L}\mat{C}\mat{e}_k
    \nonumber \\
  \mat{e}_{k+1} &= \mat{A}\mat{x}_k - \mat{A}\hat{\mat{x}}_k -
    \mat{L}\mat{C}\mat{e}_k \nonumber \\
  \mat{e}_{k+1} &= \mat{A}(\mat{x}_k - \hat{\mat{x}}_k) -
    \mat{L}\mat{C}\mat{e}_k \nonumber \\
  \mat{e}_{k+1} &= \mat{A}\mat{e}_k - \mat{L}\mat{C}\mat{e}_k \nonumber \\
  \mat{e}_{k+1} &= (\mat{A} - \mat{L}\mat{C})\mat{e}_k \label{eq:obsv_eig_calc}
\end{align}

For equation \eqref{eq:obsv_eig_calc} to have a bounded output, the eigenvalues
of $\mat{A} - \mat{L}\mat{C}$ must be within the unit circle. These eigenvalues
represent how fast the estimator converges to the true \gls{state} of the given
\gls{model}. A fast estimator converges quickly while a slow estimator avoids
amplifying noise in the measurements used to produce a \gls{state} estimate.

The effect of noise can be seen if it is modeled
\glslink{stochastic process}{stochastically} as
\begin{align*}
  \hat{\mat{x}}_{k+1} &= \mat{A}\hat{\mat{x}}_k + \mat{B}\mat{u}_k +
    \mat{L} ((\mat{y}_k + \mat{\nu}_k) - \hat{\mat{y}}_k) \\
  \intertext{where $\mat{\nu}_k$ is the measurement noise. Rearranging this
    equation yields}
  \hat{\mat{x}}_{k+1} &= \mat{A}\hat{\mat{x}}_k + \mat{B}\mat{u}_k +
    \mat{L} (\mat{y}_k - \hat{\mat{y}}_k + \mat{\nu}_k) \\
  \hat{\mat{x}}_{k+1} &= \mat{A}\hat{\mat{x}}_k + \mat{B}\mat{u}_k +
    \mat{L} (\mat{y}_k - \hat{\mat{y}}_k) + \mat{L}\mat{\nu}_k
\end{align*}

As $\mat{L}$ increases, the measurement noise is amplified.

\subsection{Separation principle}

The separation principle for linear stochastic systems states that the optimal
controller and optimal observer for the stochastic system can be designed
independently, and the combination of a stable controller and a stable observer
is itself stable.

This means that designing the optimal feedback controller for the stochastic
system can be decomposed into designing the optimal state observer, then feeding
that into the optimal controller for the deterministic system.

Consider the following state-space model.
\begin{align*}
  \mat{x}_{k+1} &= \mat{A}\mat{x}_k + \mat{B}\mat{u}_k \\
  \mat{y}_k &= \mat{C}\mat{x}_k + \mat{D}\mat{u}_k
\end{align*}

We'll use the following controller for state feedback.
\begin{equation*}
  \mat{u}_k = -\mat{K}\hat{\mat{x}}_k
\end{equation*}

With the estimation error defined as $\mat{e}_k = \mat{x}_k - \hat{\mat{x}}_k$,
we get the observer dynamics derived in equation \eqref{eq:obsv_eig_calc}.
\begin{equation*}
  \mat{e}_{k+1} = (\mat{A} - \mat{L}\mat{C})\mat{e}_k
\end{equation*}

Also, after rearranging the error equation to be
$\hat{\mat{x}}_k = \mat{x}_k - \mat{e}_k$, the controller can be rewritten as
\begin{equation*}
  \mat{u}_k = -\mat{K}(\mat{x}_k - \mat{e}_k)
\end{equation*}

Substitute this into the model.
\begin{align*}
  \mat{x}_{k+1} &= \mat{A}\mat{x}_k + \mat{B}\mat{u}_k \\
  \mat{x}_{k+1} &= \mat{A}\mat{x}_k - \mat{B}\mat{K}(\mat{x}_k - \mat{e}_k) \\
  \mat{x}_{k+1} &= (\mat{A} - \mat{B}\mat{K})\mat{x}_k + \mat{B}\mat{K}\mat{e}_k
\end{align*}

Now, we can write the closed-loop dynamics as
\begin{equation*}
  \begin{bmatrix}
    \mat{x}_{k+1} \\
    \mat{e}_{k+1}
  \end{bmatrix} =
  \begin{bmatrix}
    \mat{A} - \mat{B}\mat{K} & \mat{B}\mat{K} \\
    \mat{0} & \mat{A} - \mat{L}\mat{C}
  \end{bmatrix}
  \begin{bmatrix}
    \mat{x}_k \\
    \mat{e}_k
  \end{bmatrix}
\end{equation*}

Since the closed-loop system matrix is triangular, the eigenvalues are those of
$\mat{A} - \mat{B}\mat{K}$ and $\mat{A} - \mat{L}\mat{C}$. Therefore, the
stability of the feedback controller and observer are independent.
